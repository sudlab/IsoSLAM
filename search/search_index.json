{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Welcome to IsoSLAM","text":"<ul> <li>Introduction</li> <li>Installation</li> <li>Usage</li> <li>Workflow</li> <li>Contributing</li> <li>Extending</li> <li>API</li> </ul>"},{"location":"api/","title":"API","text":"<ul> <li><code>io</code></li> <li><code>isoslam</code></li> <li><code>logging</code></li> <li><code>processing</code></li> <li><code>summary</code></li> <li><code>utils</code></li> </ul>"},{"location":"contributing/","title":"Contributing","text":"<p>This document describes how to contribute to the development of this software.</p>"},{"location":"contributing/#bug-reports","title":"Bug Reports","text":"<p>If you find a but we need to know about it so we can fix it. Please report your bugs on our GitHub Issues page.</p>"},{"location":"contributing/#feature-requests","title":"Feature Requests","text":"<p>If you find IsoSLAM useful but think it can be improved you can make a feature request.</p>"},{"location":"contributing/#code-contributions","title":"Code Contributions","text":"<p>If you would like to fix a bug or add a new feature that is great, Pull Requests are very welcome.</p> <p>However, we have adopted a number of good software development practises that ensure the code and documentation is linted and that unit and regression tests pass both locally and on Continuous Integration. The rest of this page helps explain how to set yourself up with these various tools.</p>"},{"location":"contributing/#virtual-environments","title":"Virtual Environments","text":"<p>Use of virtual environments, particularly during development of Python packages, is encouraged. There are lots of options out there for you to choose from including...</p> <ul> <li>Miniconda</li> <li>venv</li> <li>virtualenvwrapper</li> </ul> <p>Which you choose is up to you, although you should be wary of using the Miniconda distribution from Anaconda if any of your work is carried out for or in conjunction with a commercial entity.</p>"},{"location":"contributing/#uv","title":"uv","text":"<p>Developers are using the uv package manager to setup and control environments to which end a <code>uv.lock</code> file is included in the repository. uv supports managing virtual environments so you may wish to install and use this tool at the system level to manage your virtual environments for this package.</p>"},{"location":"contributing/#cloning-the-repository","title":"Cloning the Repository","text":"<p>Once you have setup your virtual environment you should clone the repository from GitHub</p> <pre><code>cd ~/path/you/want/to/clone/to\ngit clone https://github.com/sudlab/IsoSLAM\n</code></pre>"},{"location":"contributing/#install-development","title":"Install development","text":"<p>Once you have clone the IsoSLAM repository you should install all the package along with all development and documentation dependencies in \"editable\" mode. This means you can test the changes you make in real time.</p> <pre><code>cd IsoSLAM\npip install --no-cache-dir -e .[docs,dev]\n</code></pre>"},{"location":"contributing/#git","title":"Git","text":"<p>Git is used to version control development of the package. The <code>main</code> branch on GitHub and the pre-commit hooks have protections in place that prevent committing/pushing directly to the <code>main</code> branch. This means you should create a branch to undertake development or fix bugs.</p>"},{"location":"contributing/#issues","title":"Issues","text":"<p>Ideally an issue should have been created detailing the feature request. If it is a large amount of work this should be captured in an issue labelled \"Epic\" and the steps taken to achieve all work broken down into smaller issues.</p>"},{"location":"contributing/#branch-nomenclature","title":"Branch nomenclature","text":"<p>When undertaking work on a particular issue it is useful to use informative branch names. These convey information about what the branch is for beyond simply \"<code>adding-feature-x</code>\". You should create the branch using your GitHub username, followed by the issue number and a short description of the work being undertaken. For example <code>ns-rse/31-merge-slam-3uis</code> as this allows others to know who has been undertaking the work, what issue the work relates to and has an informative name as to the nature of that work.</p>"},{"location":"contributing/#linting","title":"Linting","text":"<p>Linting is the practice of following a consistent coding style. For Python that style is defined in PEP8. By following a consistent style across a code base it is easier to read and understand the code written by others (including your past self!). We use the following linters implemented as pre-commit hooks</p> <ul> <li>Python</li> <li>Black</li> <li>Blacken-docs</li> <li>flake8</li> <li>Numpydoc</li> <li>Ruff</li> <li>Other</li> <li>Codespell (Spelling across all filesyy)</li> <li>markdownlint-cli2 (Markdown)</li> <li>prettier (Markdown, YAML)</li> </ul>"},{"location":"contributing/#pre-commit","title":"Pre-commit","text":"<p>Style checks are made using the pre-commit framework which is one of the development dependencies and should have been installed in the previous step. You can check if its is installed in your virtual environment with <code>pip show pre-commit</code>. If you have pre-commit installed install the hook using...</p> <pre><code>pre-commit install\n</code></pre> <p>This adds a file to <code>.git/hooks/pre-commit</code> that will run all of the hooks specified in <code>.pre-commit-config.yaml</code>. The first time these are run it will take a little while as a number of virtual environments are downloaded for the first time. It might be a good time to run these manually on the code base you have just cloned which should pass all checks.</p> <pre><code>pre-commit run --all-files\n</code></pre> <p>These should all pass. Now whenever you try to make a <code>git commit</code> these checks will run before the commit is made and if any fail you will be advised of what has failed. Some of the linters such as Black and Ruff will automatically correct any errors that they find and you will have to stage the files that have changed again. Not all errors can be automatically corrected (e.g. Numpydoc validation and Pylint) and you will have to manually correct these.</p>"},{"location":"contributing/#docstrings","title":"Docstrings","text":"<p>It is sensible and easiest to write informative docstrings when first defining your modules, classes and methods/functions. Doing so is a useful adie-memoire not only for others but your future self and with modern Language Servers that will, on configuration, show you the docstrings when using the functions it helps save time.</p> <p>You will find your commits fail the numpydoc-validation pre-commit hook if you do not write docstrings and will be prompted to add one.</p>"},{"location":"contributing/#testing","title":"Testing","text":"<p>We use the pytest framework with various plugins in our testing suite. When correcting bugs and adding features at a bare minimum the existing tests should not fail. Where possible we would be grateful of contributions to the test suite. This means if an edge case has been identified and a solution derived a test is added that checks the edge case is correctly handled. For new features would ideally mean writing unit-tests to ensure each function or method works as intended and for larger classes that behaviour is as expected. Sometimes tests will need updating in light of bug fixes and features which is to be expected, but remember to commit updates to tests as well as to code to ensure the Continuous Integration tests pass.</p>"},{"location":"contributing/#pytest-testmon","title":"Pytest-testmon","text":"<p>To shorten the feedback loop during development the pytest-testmon plugin is used as a pre-commit hook so that only the tests affected by the changes that are being committed are run. This requires that on first installing the package you create a local database of the state of the tests by running the following...</p> <pre><code>pytest --test-mon\n</code></pre> <p>This creates the files <code>.testmondata</code> which stores the current state of tests. Once created commits will only run affected tests. However if your environment has changed, such as adding new packages or updating installed packages you will have to recreate the database.</p>"},{"location":"contributing/#pull-requests","title":"Pull Requests","text":"<p>Once you have made your changes and committed them you will at some point wish to make a Pull Request to merge them into the <code>main</code> branch.</p> <p>In order to keep Git history clean and easier to understand you can perform an interactive <code>git rebase -i</code> on your feature branch to squash related commits and tidy up your commit history.</p> <p>When your branch is ready for merging with <code>main</code> open a Pull Request. You can use the GitHub keywords of <code>close[s|d]</code>/<code>fix[es|ed]</code> / <code>resolve[s|d]</code> followed by the issue number in the body of your commit message which will change the status of the issue to \"Closed\" when the Pull Request is merged.</p> <p>Pull Requests will be reviewed in a timely and hopefully constructive manner.</p>"},{"location":"extending/","title":"Extending IsoSLAM","text":"<p>The modular nature of IsoSLAM and its use of <code>ruffus</code> and <code>cgat</code> mean that it is relatively straight-forward to add additional steps or processing.</p>"},{"location":"extending/#overview","title":"Overview","text":"<ol> <li>Add a new module to <code>isoslam/&lt;module_name&gt;.py</code> and write functions, include numpydoc strings so the    functions/classes are documented.</li> <li>Add all options to <code>isoslam/default_config.yaml</code>.</li> <li>Add a <code>sub-parser</code> to <code>isoslam/processing.py</code> with command line options for all arguments to your function.</li> <li>Add a <code>process_&lt;module_name&gt;</code> function to <code>isoslam/processing.py</code>.</li> <li>Add an entry to the documentation to build the API documentation automatically.</li> </ol> <p>By way of example the implementation of the <code>isoslam summary</code> sub-command is explained.</p>"},{"location":"extending/#adding-a-module","title":"Adding a module","text":"<p>This is probably the most flexible part, you can add the module as you see fit. You can use Object Orientated approach and write a class or classes or functional programming and a series.</p> <p>However you will need a single function that takes the input and various options.</p>"},{"location":"extending/#example","title":"Example","text":"<p>The <code>summary</code> module appends multiple files produced from running IsoSLAM on a series of inputs and appends the data. These are then summarised by a set of variables to give the number of counts.</p>"},{"location":"extending/#isoslamsummarypy","title":"<code>isoslam/summary.py</code>","text":"<pre><code>\"\"\"Functions for summarising output.\"\"\"\n\nimport pandas as pd\n\nfrom isoslam import io\n\n\ndef append_files(pattern: str = \"**/*.tsv\", separator: str = \"\\t\") -&gt; pd.DataFrame:\n    \"\"\"\n    Append a set of files into a Pandas DataFrames.\n\n    Parameters\n    ----------\n    pattern : str\n        File name pattern to search for.\n    separator : str\n        Separator/delimiter used in files.\n\n    Returns\n    -------\n    pd.DataFrame\n        A Pandas DataFrames of each file found.\n    \"\"\"\n    _data = io.load_files(pattern, separator)\n    all_data = [data.assign(filename=key) for key, data in _data.items()]\n    return pd.concat(all_data)\n\n\ndef summary_counts(\n    file_pattern: str = \"**/*.tsv\",\n    separator: str = \"\\t\",\n    groupby: list[str] | None = None,\n    dropna: bool = True,\n) -&gt; pd.DataFrame:\n    \"\"\"\n    Count the number of assigned read pairs.\n\n    Groups the data by\n\n    Parameters\n    ----------\n    file_pattern : str\n        File name pattern to search for.\n    separator : str\n        Separator/delimiter used in files.\n    groupby : list[str]\n        List of variables to group the counts by.\n    dropna : book\n        Whether to drop rows with ``NA`` values.\n\n    Returns\n    -------\n    pd.DataFrame\n        A Pandas DataFrames of each file found.\n    \"\"\"\n    if groupby is None:\n        groupby = [\"Transcript_id\", \"Chr\", \"Strand\", \"Start\", \"End\", \"Assignment\", \"Conversions\", \"filename\"]\n    _data = append_files(file_pattern, separator)\n    _data[\"one_or_more_conversion\"] = _data[\"Conversions\"] &gt;= 1\n    groupby.append(\"one_or_more_conversion\")\n    return _data.value_counts(subset=groupby, dropna=dropna).reset_index()\n</code></pre> <p>This included writing a function to search for files with a given <code>pattern</code> and load them using the specified <code>separator</code>. As this is an Input/Output operation the functions were added to the <code>isoslam/io.py</code> module.</p>"},{"location":"extending/#iopy","title":"<code>io.py</code>","text":"<pre><code>def _find_files(pattern: str = \"**/*.tsv\") -&gt; Generator:  # type: ignore[type-arg]\n    \"\"\"\n    Find files that match the given pattern.\n\n    Parameters\n    ----------\n    pattern : str\n        Pattern (regular expression) of files to search for.\n\n    Returns\n    -------\n    Generator[_P, None, None]\n        A generator of files found that match the given pattern.\n    \"\"\"\n    pwd = Path.cwd()\n    return pwd.rglob(pattern)\n\n\ndef load_files(pattern: str = \"**/*.tsv\", sep: str = \"\\t\") -&gt; dict[str, pd.DataFrame]:\n    \"\"\"\n    Read a set of files into a list of Pandas DataFrames.\n\n    Parameters\n    ----------\n    pattern : str\n        File name pattern to search for.\n    sep : str\n        Separator/delimiter used in files.\n\n    Returns\n    -------\n    list[pd.DataFrame]\n        A list of Pandas DataFrames of each file found.\n    \"\"\"\n    return {x.stem: pd.read_csv(x, sep=sep) for x in _find_files(pattern)}\n</code></pre>"},{"location":"extending/#add-options-to-isoslamdefault_configyaml","title":"Add options to <code>isoslam/default_config.yaml</code>","text":"<p>We want to be consistent across the configuration file, which resides in <code>isoslam/default_config.yaml</code> and is used when generating configurations using <code>isoslam create-config</code>. To do so the function parameters, in this example <code>summary_counts()</code>, should be used as entries in the <code>isoslam/default_config.yaml</code>.</p>"},{"location":"extending/#example_1","title":"Example","text":"<p>The top level of a modules configuration should match the module name, here <code>summary_counts</code>. Each entry is a key/value pair that corresponds to the arguments of the function, and so we have <code>file_pattern</code>, <code>separator</code>, <code>groupby</code> and <code>output</code> with their various options.</p> <pre><code>summary_counts:\n  file_pattern: \"**/*.tsv\"\n  separator: \"\\t\"\n  groupby:\n    - Transcript_id\n    - Chr\n    - Strand\n    - Start\n    - End\n    - Assignment\n    - Conversions\n    - filename\n  output:\n    outfile: summary_counts.tsv\n    sep: \"\\t\"\n    index: false\n</code></pre>"},{"location":"extending/#add-a-sub-parser-to-isoslamprocessingpy","title":"Add a sub-parser to <code>isoslam/processing.py</code>","text":"<p>The function <code>create_parser()</code> is responsible for creating the <code>isoslam</code> arguments and sub-parsers and their associated arguments.</p> <p>Define a sub-parser and <code>add_argument()</code> for each option that is available. Keep names consistent with the arguments of the main function you have written above and in turn the configuration values in <code>isoslam/default_config.yaml</code>.</p>"},{"location":"extending/#example_2","title":"Example","text":"<p><pre><code>    # Summarise counts sub-parser\n    summary_counts_parser = subparsers.add_parser(\n        \"summary-counts\",\n        description=\"Summarise the counts.\",\n        help=\"Summarise the counts.\",\n    )\n    summary_counts_parser.add_argument(\n        \"--file-pattern\",\n        dest=\"file_pattern\",\n        type=str,\n        required=False,\n        default=\"*_summarized.tsv\",\n        help=\"Regular expression for summarized files to process.\",\n    )\n    summary_counts_parser.add_argument(\n        \"--outfile\",\n        dest=\"outfile\",\n        type=Path,\n        required=False,\n        default=\"summary_counts.tsv\",\n        help=\"Output filename to save results to, will be nested under 'output_dir'.\",\n    )\n    summary_counts_parser.add_argument(\n        \"--separator\",\n        dest=\"sep\",\n        type=str,\n        required=False,\n        default=\"\\t\",\n        help=\"Field separator to use in output file, default is '\\t' but other values (e.g. ',' are allowed).\",\n    )\n    summary_counts_parser.set_defaults(func=summarise_counts)\n</code></pre> The last line here <code>.set_defaults(func=summarise_counts)</code> is the function that will be called when running the subcommand and corresponds to the function</p>"},{"location":"extending/#documentation","title":"Documentation","text":"<p>To have the documentation automatically built from the docstrings you have written for your functions you need to add a <code>docs/api/&lt;module_name&gt;.md</code> that corresponds to each of the modules you have introduced and add a title, short description and <code>isoslam.&lt;module_name&gt;</code>. If you have introduced more than one module then you will have to add a corresponding file for each module/sub-module you have introduced. If these are nested please mirror the nesting structure in the documentation.</p>"},{"location":"extending/#example_3","title":"Example","text":"<pre><code># Summary\n\n::: isoslam.summary\n    handler: python\n    options:\n      docstring_style:\n        numpy\n      rendering:\n        show_signature_annotations: true\n</code></pre>"},{"location":"installation/","title":"Installation","text":"<p>Ideally you should install IsoSLAM under a Python Virtual Environment. Details of how to work with and use these is beyond the scope of this documentation but some advice can be found in the contributing section.</p>"},{"location":"installation/#dependencies","title":"Dependencies","text":"<p>There are a number of external dependencies required for running IsoSLAM.</p> <ul> <li><code>samtools</code> / <code>bcftools</code> are both required and can be downloaded from htslib</li> <li>VarScan (documentation)</li> <li>subread (documentation)</li> </ul>"},{"location":"installation/#indirect-dependencies","title":"Indirect Dependencies","text":"<p>The pipeline for running the various steps in processing data rely on the cgat tools. These have two external dependencies themselves and if you wish to use such a pipeline will have to install these.</p> <ul> <li>bedtools</li> <li>wigToBigWig - the minimal tools may suffice.</li> </ul>"},{"location":"installation/#gnulinux","title":"GNU/Linux","text":""},{"location":"installation/#arch-linux","title":"Arch Linux","text":"<p>If you use Arch Linux the packages are available in the Arch Linux User Repository (AUR)</p> <pre><code>mkdir ~/aur &amp;&amp; cd ~/aur\ngit clone https://aur.archlinux.org/htslib.git\ngit clone https://aur.archlinux.org/samtools.git\ngit clone https://aur.archlinux.org/bcftools.git\ngit clone https://aur.archlinux.org/subread.git\ngit clone https://aur.archlinux.org/bedtools.git\ncd htslib\nmakepkg -sri\ncd ../bcftools\nmakepkg -sri\ncd ../samtools\nmakepkg -sri\ncd ../subread\nmakepkg -sri\ncd ../bedtools\nmakepkg -sri\n</code></pre> <p>varscan is written in Java, you need to download the latest release</p> <p>You can make a wrapper to run this, assuming you have saved the file to <code>~/.local/jar/VarScan.v2.4.6.jar</code> (adjust for the version you have downloaded), you can create the following short script and make it executable, placing it in your <code>$PATH</code> (the example below uses <code>~/.local/bin/</code>)</p> <pre><code>#!/bin/bash\n\njava -jar ~/.local\"\n</code></pre> <p>Make the file executable and you can then run <code>varscan</code></p> <pre><code>chmod 755 ~/.local/bin/varscan\nvarscan\nVarScan v2.4.6\n\n***NON-COMMERCIAL VERSION***\n\nUSAGE: java -jar VarScan.jar [COMMAND] [OPTIONS]\n\nCOMMANDS:\n pileup2snp  Identify SNPs from a pileup file\n pileup2indel  Identify indels a pileup file\n pileup2cns  Call consensus and variants from a pileup file\n mpileup2snp  Identify SNPs from an mpileup file\n mpileup2indel  Identify indels an mpileup file\n mpileup2cns  Call consensus and variants from an mpileup file\n\n somatic   Call germline/somatic variants from tumor-normal pileups\n mpileup2somatic  Call germline/somatic variants in multi-tumor-normal mpileup (beta feature in v2.4.5)\n copynumber  Determine relative tumor copy number from tumor-normal pileups\n readcounts  Obtain read counts for a list of variants from a pileup file\n\n filter   Filter SNPs by coverage, frequency, p-value, etc.\n somaticFilter  Filter somatic variants for clusters/indels\n fpfilter  Apply the false-positive filter\n\n processSomatic  Isolate Germline/LOH/Somatic calls from output\n copyCaller  GC-adjust and process copy number changes from VarScan copynumber output\n compare   Compare two lists of positions/variants\n limit   Restrict pileup/snps/indels to ROI positions\n</code></pre>"},{"location":"installation/#gentoo","title":"Gentoo","text":"<p><code>samtools</code> and <code>bcftools</code> are available in Portage, to install.</p> <pre><code>emerge --sync &amp;&amp; emerge -av samtools bcftools bedtools ucsc-genome-browser\n</code></pre> <p>to write - how to install</p>"},{"location":"installation/#ubuntudebian","title":"Ubuntu/Debian","text":"<p>All three packages are available for Debian based repositories.</p> <pre><code>sudo apt-get update\nsudo apt-get install samtools bcftools bedtools\n</code></pre>"},{"location":"installation/#ucsc-genome-browser","title":"UCSC Genome Browser","text":"<p>This needs installing from source across all distributions. The minimal should suffice.</p> <pre><code>git clone git@github.com:ucscGenomeBrowser/kent-core.git\ncd kent-core\nsudo make\n</code></pre>"},{"location":"installation/#source-install","title":"Source Install","text":"<p>The releases pages includes instructions on how to build the package from source, but note that you will then have to manually update the packages when new releases are made.</p>"},{"location":"installation/#windows","title":"Windows","text":"<p>To write at some point.</p>"},{"location":"installation/#osx","title":"OSX","text":"<p>To write at some point.</p>"},{"location":"installation/#conda","title":"Conda","text":"<p>If you don't have the ability to install these programmes at the system level an alternative is to use a Conda environment.</p> <pre><code>conda create -n isoslam python==3.12\nconda activate isoslam\nconda install mamba\nmamba install -c conda-forge -c bioconda cgat-apps\nmamba install -c conda-forge -c bioconda samtools bcftools\nmamba install -c conda-forge -c bioconda subread\nmamba install -c conda-forge -c bioconda varscan\n</code></pre>"},{"location":"installation/#github","title":"GitHub","text":"<p>There are two methods of installing IsoSLAM from its GitHub repository.</p>"},{"location":"installation/#cloning","title":"Cloning","text":"<p>You can clone the repository and install from the clone.</p> <pre><code>git clone git@github.com:sudlab/IsoSLAM.git\ncd IsoSLAM\npip install -e .\n</code></pre> <p>By using the <code>-e</code> (editable) flag it means you can switch branches.</p>"},{"location":"installation/#pip-from-github","title":"<code>pip</code> from GitHub","text":"<p>The package installer for Python pip can be used to install packages directly from their version control homepage.</p> <pre><code>pip install git+ssh://git@github.com/IsoSLAM\n</code></pre> <p>If you want to install a specific branch or commit you can do so.</p> <pre><code>pip install git+ssh://git@github.com/IsoSLAM@&lt;branch-name&gt;\npip install git+ssh://git@github.com/IsoSLAM@&lt;commit-hash&gt;\n</code></pre>"},{"location":"installation/#pypi","title":"PyPI","text":"<p>We intend to publish IsoSLAM to the Python Package Index (PyPI). When available you will be able to install with</p> <pre><code>pip install IsoSLAM\n</code></pre> <p>NB IsoSLAM is NOT currently available on PyPI.</p>"},{"location":"introduction/","title":"Introduction","text":"<p>IsoSLAM is a Python package for processing the output of...</p>"},{"location":"usage/","title":"Usage","text":"<p>TO BE WRITTEN Awaiting refactoring of code base.</p>"},{"location":"workflow/","title":"Workflow","text":"<p>This page gives an overview of the workflow undertaken by IsoSLAM.</p> <p>WORK IN PROGRESS - This is very much a work in progress and is not yet complete. Contributions are welcome.</p> <pre><code>%%{init: {'theme': 'base', 'gitGraph': {'rotateCommitLabel': true}\n         }\n}%%\ngraph TD;\n\n  subgraph input\n  A1([STAR Aligned Reads]) --&gt; B1\n  A2([.FASTA file]) --&gt; B1\n  A3([Contigs]) --&gt; B1\n  A4([.BED file]) --&gt; B1\n  A5([.GTF file]) --&gt; B1\n  end\n\n  subgraph Python\n\n  B1[pipeline.py] --&gt; B2\n\n\n  style A1 fill:#648FFF,stroke:#000000\n  style A2 fill:#648FFF,stroke:#000000\n  style A3 fill:#648FFF,stroke:#000000\n  style A4 fill:#648FFF,stroke:#000000\n  style A5 fill:#648FFF,stroke:#000000\n  end\n\n  B2([Pipeline_slam_3UIs.py]) --&gt; statistics\n\n\n  subgraph statistics\n  D1([get_pair_pvalues])\n  D2([get_pair_half_lives])\n  D3([get_over_time_pvalues])\n  D4([get_interaction_over_time_pvals])\n\n  end\n  style B1 fill:#00FF90,stroke:#000000\n  style B2 fill:#00FF90,stroke:#000000\n\n\n\n\n\n  style D1 fill:#FE6100,stroke:#000000\n  style D2 fill:#FE6100,stroke:#000000\n  style D3 fill:#FE6100,stroke:#000000\n  style D4 fill:#FE6100,stroke:#000000\n\n  style E1 fill:#FEE100,stroke:#000000\n</code></pre>"},{"location":"workflow/#isoslam","title":"IsoSLAM","text":"<p>A number of pre-processing steps are undertaken prior to IsoSLAM work being done. The following is work in progress as the code is refactored.</p> <ol> <li>Iterate over <code>.bam</code> file and pair segments. If two or more <code>AlignedSegments</code> with the same <code>query_name</code> are found    then <code>n &gt; 1</code> segments are dropped.</li> <li>Pairs of segments (individual <code>AlignedSegments</code>) are then assessed and if they are <code>Assigned</code> the <code>start</code>, <code>end</code>,    <code>length</code>, <code>status</code> (i.e. <code>Assigned</code>), <code>transcript_id</code>, <code>block_start</code> and <code>block_end</code> are extracted.</li> </ol>"},{"location":"workflow/#updating","title":"Updating","text":"<p>The above diagram is written in Mermaid. You can view the source code in the IsoSLAM repository and develop/modify it using the Mermaid Live Editor and make pull-requests to update this documentation.</p>"},{"location":"api/io/","title":"IO Modules","text":"<p>Module for reading and writing files.</p>"},{"location":"api/io/#isoslam.io.create_config","title":"<code>create_config(args=None)</code>","text":"<p>Write the default configuration file to disk.</p> <p>Parameters:</p> Name Type Description Default <code>args</code> <code>Namespace | None</code> <p>Optional arguments to parse.</p> <code>None</code> Source code in <code>isoslam/io.py</code> <pre><code>def create_config(args: argparse.Namespace | None = None) -&gt; None:\n    \"\"\"\n    Write the default configuration file to disk.\n\n    Parameters\n    ----------\n    args : argparse.Namespace | None\n        Optional arguments to parse.\n    \"\"\"\n    filename = \"config\" if args.filename is None else args.filename  # type: ignore [union-attr]\n    output_dir = Path(\"./\") if args.output_dir is None else Path(args.output_dir)  # type: ignore [union-attr]\n    output_dir.mkdir(parents=True, exist_ok=True)\n    config_path = resources.files(__package__) / \"default_config.yaml\"\n    config = config_path.read_text()\n\n    if \".yaml\" not in str(filename) and \".yml\" not in str(filename):\n        create_config_path = output_dir / f\"{filename}.yaml\"\n    else:\n        create_config_path = output_dir / filename\n\n    with create_config_path.open(\"w\", encoding=\"utf-8\") as f:\n        f.write(f\"# Config file generated {_get_date_time()}\\n\")\n        f.write(f\"{CONFIG_DOCUMENTATION_REFERENCE}\")\n        f.write(config)\n    logger.info(f\"A sample configuration file has been written to : {str(create_config_path)}\")\n    logger.info(CONFIG_DOCUMENTATION_REFERENCE)\n</code></pre>"},{"location":"api/io/#isoslam.io.data_frame_to_file","title":"<code>data_frame_to_file(data, output_dir='./output/', outfile='summary_counts.csv', sep='\\t', **kwargs)</code>","text":"<p>Write a Pandas DataFrame to disk.</p> <p>Parameters:</p> Name Type Description Default <code>data</code> <code>DataFrame</code> <p>Pandas DataFrame to write to disk.</p> required <code>output_dir</code> <code>str | Path</code> <p>Location to write the output to, default is ''./output''.capitalize.</p> <code>'./output/'</code> <code>outfile</code> <code>str</code> <p>Filename to write data to.</p> <code>'summary_counts.csv'</code> <code>sep</code> <code>str</code> <p>Separator to use in output file.</p> <code>'\\t'</code> <code>**kwargs</code> <code>dict[Any, Any]</code> <p>Dictionary of keyword arguments to pass to ''pandas.DataFrame.to_csv()''.</p> <code>{}</code> Source code in <code>isoslam/io.py</code> <pre><code>def data_frame_to_file(\n    data: pd.DataFrame,\n    output_dir: str | Path = \"./output/\",\n    outfile: str = \"summary_counts.csv\",\n    sep: str = \"\\t\",\n    **kwargs: dict[Any, Any],\n) -&gt; None:\n    \"\"\"\n    Write a Pandas DataFrame to disk.\n\n    Parameters\n    ----------\n    data : pd.DataFrame\n        Pandas DataFrame to write to disk.\n    output_dir : str | Path\n        Location to write the output to, default is ''./output''.capitalize.\n    outfile : str\n        Filename to write data to.\n    sep : str\n        Separator to use in output file.\n    **kwargs\n        Dictionary of keyword arguments to pass to ''pandas.DataFrame.to_csv()''.\n    \"\"\"\n    outdir_file = Path(output_dir) / f\"{outfile}\"\n    data.to_csv(outdir_file, sep=sep, **kwargs)\n    logger.debug(f\"File written to : {outdir_file}\")\n</code></pre>"},{"location":"api/io/#isoslam.io.load_and_update_config","title":"<code>load_and_update_config(args)</code>","text":"<p>Load a configuration file to dictionary and update entries with user supplied arguments.</p> <p>If ''args'' does not contain any value for ''args.config_file'' the default configuration (''isoslam/default_config.yaml'') is loaded, otherwise the user specified configuration is loaded.</p> <p>Once the configuration is loaded any user specified options update the dictionary.</p> <p>Parameters:</p> Name Type Description Default <code>args</code> <code>Namespace</code> <p>Arguments supplied by user.</p> required <p>Returns:</p> Type Description <code>dict[str:Any]</code> <p>Dictionary of configuration optionsupdated with user specified options.</p> Source code in <code>isoslam/io.py</code> <pre><code>def load_and_update_config(args: argparse.Namespace | None) -&gt; dict[str, Any]:\n    \"\"\"\n    Load a configuration file to dictionary and update entries with user supplied arguments.\n\n    If ''args'' does not contain any value for ''args.config_file'' the default configuration\n    (''isoslam/default_config.yaml'') is loaded, otherwise the user specified configuration is loaded.\n\n    Once the configuration is loaded any user specified options update the dictionary.\n\n    Parameters\n    ----------\n    args : argparse.Namespace\n        Arguments supplied by user.\n\n    Returns\n    -------\n    dict[str: Any]\n        Dictionary of configuration optionsupdated with user specified options.\n    \"\"\"\n    config = read_yaml() if vars(args)[\"config_file\"] is None else read_yaml(vars(args)[\"config_file\"])\n    return utils.update_config(config, vars(args))  # type: ignore[arg-type]\n</code></pre>"},{"location":"api/io/#isoslam.io.load_file","title":"<code>load_file(file_path)</code>","text":"<p>Load files of different types.</p> <p>Supports the following file types...</p> <ul> <li><code>.bam</code> - The sequence data that is to be analysed.</li> <li><code>.bed</code> - The locations of introns/splice junctions.</li> <li><code>.gtf</code> - Transcript structures from which the <code>.bed</code> file is derived.</li> <li><code>.vcf</code> - Locations of known sequences difference from the reference sequence.</li> </ul> <p>Parameters:</p> Name Type Description Default <code>file_path</code> <code>str | Path</code> <p>Path to file to load.</p> required <p>Returns:</p> Type Description <code>Any</code> <p>Returns the loaded file as an object.</p> Source code in <code>isoslam/io.py</code> <pre><code>def load_file(file_path: str | Path) -&gt; Any:\n    \"\"\"\n    Load files of different types.\n\n    Supports the following file types...\n\n    * ``.bam`` - The sequence data that is to be analysed.\n    * ``.bed`` - The locations of introns/splice junctions.\n    * ``.gtf`` - Transcript structures from which the ``.bed`` file is derived.\n    * ``.vcf`` - Locations of known sequences difference from the reference sequence.\n\n    Parameters\n    ----------\n    file_path : str | Path\n        Path to file to load.\n\n    Returns\n    -------\n    Any\n        Returns the loaded file as an object.\n    \"\"\"\n    file_suffix = Path(file_path).suffix\n    if file_suffix == \".gz\":\n        file_suffix = \"\".join(Path(file_path).suffixes)\n    loader = _get_loader(file_suffix)\n    return loader(file_path)\n</code></pre>"},{"location":"api/io/#isoslam.io.load_files","title":"<code>load_files(pattern='**/*.tsv', sep='\\t')</code>","text":"<p>Read a set of files into a list of Pandas DataFrames.</p> <p>Parameters:</p> Name Type Description Default <code>pattern</code> <code>str</code> <p>File name pattern to search for.</p> <code>'**/*.tsv'</code> <code>sep</code> <code>str</code> <p>Separator/delimiter used in files.</p> <code>'\\t'</code> <p>Returns:</p> Type Description <code>list[DataFrame]</code> <p>A list of Pandas DataFrames of each file found.</p> Source code in <code>isoslam/io.py</code> <pre><code>def load_files(pattern: str = \"**/*.tsv\", sep: str = \"\\t\") -&gt; dict[str, pd.DataFrame]:\n    \"\"\"\n    Read a set of files into a list of Pandas DataFrames.\n\n    Parameters\n    ----------\n    pattern : str\n        File name pattern to search for.\n    sep : str\n        Separator/delimiter used in files.\n\n    Returns\n    -------\n    list[pd.DataFrame]\n        A list of Pandas DataFrames of each file found.\n    \"\"\"\n    return {x.stem: pd.read_csv(x, sep=sep) for x in _find_files(pattern)}\n</code></pre>"},{"location":"api/io/#isoslam.io.read_yaml","title":"<code>read_yaml(filename=None)</code>","text":"<p>Read a YAML file.</p> <p>Parameters:</p> Name Type Description Default <code>filename</code> <code>Union[str, Path]</code> <p>YAML file to read.</p> <code>None</code> <p>Returns:</p> Type Description <code>Dict</code> <p>Dictionary of the file.</p> Source code in <code>isoslam/io.py</code> <pre><code>def read_yaml(filename: str | Path | None = None) -&gt; dict[str, Any] | None:\n    \"\"\"\n    Read a YAML file.\n\n    Parameters\n    ----------\n    filename : Union[str, Path]\n        YAML file to read.\n\n    Returns\n    -------\n    Dict\n        Dictionary of the file.\n    \"\"\"\n    if filename is None:\n        filename = resources.files(__package__) / \"default_config.yaml\"  # type: ignore[assignment]\n    with Path(filename).open(encoding=\"utf-8\") as f:  # type: ignore[arg-type]\n        try:\n            yaml_file = YAML(typ=\"safe\")\n            return yaml_file.load(f)  # type: ignore[no-any-return]\n        except YAMLError as exception:\n            logger.error(exception)\n            return {}\n</code></pre>"},{"location":"api/io/#isoslam.io.write_yaml","title":"<code>write_yaml(config, output_dir, config_file='config.yaml', header_message=None)</code>","text":"<p>Write a configuration (stored as a dictionary) to a YAML file.</p> <p>Parameters:</p> Name Type Description Default <code>config</code> <code>dict</code> <p>Configuration dictionary.</p> required <code>output_dir</code> <code>Union[str, Path]</code> <p>Path to save the dictionary to as a YAML file (it will be called 'config.yaml').</p> required <code>config_file</code> <code>str</code> <p>Filename to write to.</p> <code>'config.yaml'</code> <code>header_message</code> <code>str</code> <p>String to write to the header message of the YAML file.</p> <code>None</code> Source code in <code>isoslam/io.py</code> <pre><code>def write_yaml(\n    config: dict,  # type: ignore[type-arg]\n    output_dir: str | Path,\n    config_file: str = \"config.yaml\",\n    header_message: str | None = None,\n) -&gt; None:\n    \"\"\"\n    Write a configuration (stored as a dictionary) to a YAML file.\n\n    Parameters\n    ----------\n    config : dict\n        Configuration dictionary.\n    output_dir : Union[str, Path]\n        Path to save the dictionary to as a YAML file (it will be called 'config.yaml').\n    config_file : str\n        Filename to write to.\n    header_message : str\n        String to write to the header message of the YAML file.\n    \"\"\"\n    output_config = Path(output_dir) / config_file\n    # Revert PosixPath items to string\n    config = _path_to_str(config)\n\n    if header_message:\n        header = f\"# {header_message} : {_get_date_time()}\\n\" + CONFIG_DOCUMENTATION_REFERENCE\n    else:\n        header = f\"# Configuration from IsoSLAM run completed : {_get_date_time()}\\n\" + CONFIG_DOCUMENTATION_REFERENCE\n    output_config.write_text(header, encoding=\"utf-8\")\n\n    yaml = YAML(typ=\"safe\")\n    with output_config.open(\"a\", encoding=\"utf-8\") as f:\n        try:\n            yaml.dump(config, f)\n        except YAMLError as exception:\n            logger.error(exception)\n</code></pre>"},{"location":"api/isoslam/","title":"IsoSLAM","text":"<p>This module contains the main functions that constitute the IsoSLAM package.</p> <p>IsoSLAM module.</p>"},{"location":"api/isoslam/#isoslam.isoslam.extract_features_from_pair","title":"<code>extract_features_from_pair(pair)</code>","text":"<p>Extract features from a pair of reads.</p> <p>Parameters:</p> Name Type Description Default <code>pair</code> <code>list[AlignedSegment]</code> <p>A list of two aligned segments from <code>pysam</code>.</p> required <p>Returns:</p> Type Description <code>dic[str, dict[str, Any]]</code> <p>Returns a nested dictionaries of the <code>start</code>, <code>end</code> and <code>length</code> of each read.</p> Source code in <code>isoslam/isoslam.py</code> <pre><code>def extract_features_from_pair(pair: list[AlignedSegment]) -&gt; dict[str, dict[str, Any]]:\n    \"\"\"\n    Extract features from a pair of reads.\n\n    Parameters\n    ----------\n    pair : list[AlignedSegment]\n        A list of two aligned segments from ``pysam``.\n\n    Returns\n    -------\n    dic[str, dict[str, Any]]\n        Returns a nested dictionaries of the ``start``, ``end`` and ``length`` of each read.\n    \"\"\"\n    return {\n        \"read1\": extract_features_from_read(pair[0]),\n        \"read2\": extract_features_from_read(pair[1]),\n    }\n</code></pre>"},{"location":"api/isoslam/#isoslam.isoslam.extract_features_from_read","title":"<code>extract_features_from_read(read)</code>","text":"<p>Extract start, end and length from an aligned segment read.</p> <p>Parameters:</p> Name Type Description Default <code>read</code> <code>AlignedSegment</code> <p>An aligned segment read from <code>pysam</code>.</p> required <p>Returns:</p> Type Description <code>dict[str, Any]</code> <p>Dictionary of <code>start</code>, <code>end</code> and <code>length</code> of the segment.</p> Source code in <code>isoslam/isoslam.py</code> <pre><code>def extract_features_from_read(read: AlignedSegment) -&gt; dict[str, int | str | None | tuple[int, int]]:\n    \"\"\"\n    Extract start, end and length from an aligned segment read.\n\n    Parameters\n    ----------\n    read : AlignedSegment\n        An aligned segment read from ``pysam``.\n\n    Returns\n    -------\n    dict[str, Any]\n        Dictionary of ``start``, ``end`` and ``length`` of the segment.\n    \"\"\"\n    block_start, block_end = zip(*read.get_blocks())\n    try:\n        status = read.get_tag(\"XS\")\n    except KeyError:\n        status = None\n    try:\n        transcript = read.get_tag(\"XT\")\n    except KeyError:\n        transcript = None\n    return {\n        \"start\": read.reference_start,\n        \"end\": read.reference_end,\n        \"length\": read.reference_length,\n        \"status\": status,\n        \"transcript\": transcript,\n        \"block_start\": block_start,\n        \"block_end\": block_end,\n    }\n</code></pre>"},{"location":"api/isoslam/#isoslam.isoslam.extract_segment_pairs","title":"<code>extract_segment_pairs(bam_file)</code>","text":"<p>Extract pairs of AlignedSegments from a <code>.bam</code> file.</p> <p>When there are two adjacent <code>AlignedSegments</code> with the same <code>query_name</code> only the first is paired, subsequent segments are dropped.</p> <p>Parameters:</p> Name Type Description Default <code>bam_file</code> <code>str | Path</code> <p>Path to a <code>.bam</code> file.</p> required <p>Yields:</p> Type Description <code>Generator</code> <p>Itterable of paired segments.</p> Source code in <code>isoslam/isoslam.py</code> <pre><code>def extract_segment_pairs(bam_file: str | Path) -&gt; Generator[AlignedSegment]:\n    \"\"\"\n    Extract pairs of AlignedSegments from a ``.bam`` file.\n\n    When there are two adjacent ``AlignedSegments`` with the same ``query_name`` only the first is paired, subsequent\n    segments are dropped.\n\n    Parameters\n    ----------\n    bam_file : str | Path\n        Path to a ``.bam`` file.\n\n    Yields\n    ------\n    Generator\n        Itterable of paired segments.\n    \"\"\"\n    previous_read: str | None = None\n    pair: list[AlignedSegment] = []\n    for read in io.load_file(bam_file):\n        # Return pairs of reads, i.e. not on first pass, nor if query_name matches the previous read\n        if previous_read is not None and previous_read != read.query_name:\n            yield pair\n            pair = []\n            previous_read = read.query_name\n        previous_read = read.query_name\n        pair.append(read)\n    # Don't forget to return the last pair!\n    yield pair\n</code></pre>"},{"location":"api/isoslam/#isoslam.isoslam.extract_strand_transcript","title":"<code>extract_strand_transcript(gtf_file)</code>","text":"<p>Extract strand and transcript ID data from <code>.gtf</code> file.</p> <p>Parameters:</p> Name Type Description Default <code>gtf_file</code> <code>Path | str</code> <p>Path to a 'gtf' file.</p> required <p>Returns:</p> Type Description <code>tuple[dict[str, tuple[str]], dict[str, tuple[str]]]</code> <p>Two dictionaries are returned, one of the <code>strand</code> the other of the <code>transcript_id</code> both using the <code>gene_id</code> as the key.</p> Source code in <code>isoslam/isoslam.py</code> <pre><code>def extract_strand_transcript(gtf_file: str | Path) -&gt; tuple[defaultdict[Any, Any], defaultdict[Any, list[Any]]]:\n    \"\"\"\n    Extract strand and transcript ID data from ``.gtf`` file.\n\n    Parameters\n    ----------\n    gtf_file : Path | str\n        Path to a 'gtf' file.\n\n    Returns\n    -------\n    tuple[dict[str, tuple[str]], dict[str, tuple[str]]]\n        Two dictionaries are returned, one of the ``strand`` the other of the ``transcript_id`` both using the\n        ``gene_id`` as the key.\n    \"\"\"\n    strand = defaultdict(str)\n    transcript = defaultdict(list)\n    for entry in io.load_file(gtf_file):\n        if not entry.feature == \"transcript\":\n            continue\n        strand[entry.gene_id] = entry.strand\n        transcript[entry.gene_id].append(entry.transcript_id)\n    logger.info(f\"Extracted features from : {gtf_file}\")\n    return (strand, transcript)\n</code></pre>"},{"location":"api/isoslam/#isoslam.isoslam.extract_transcripts","title":"<code>extract_transcripts(bed_file)</code>","text":"<p>Extract features from <code>.bed</code> file and return as a dictionary indexed by <code>transcript_id</code>.</p> <p>Parameters:</p> Name Type Description Default <code>bed_file</code> <code>str | Path</code> <p>Path, as string or pathlib Path, to a <code>.bed</code> file.</p> required <p>Returns:</p> Type Description <code>dict[Any, list[tuple[Any, int, int, Any, Any]]]</code> <p>Dictionary of <code>chromosome</code>, <code>start</code>, <code>end</code>, <code>transcript_id</code> and <code>bedstrand</code> indexed by <code>transcript_id</code>.</p> Source code in <code>isoslam/isoslam.py</code> <pre><code>def extract_transcripts(bed_file: str | Path) -&gt; dict[Any, list[tuple[Any, int, int, Any, Any]]]:\n    \"\"\"\n    Extract features from ``.bed`` file and return as a dictionary indexed by ``transcript_id``.\n\n    Parameters\n    ----------\n    bed_file : str | Path\n        Path, as string or pathlib Path, to a ``.bed`` file.\n\n    Returns\n    -------\n    dict[Any, list[tuple[Any, int, int, Any, Any]]]\n        Dictionary of ``chromosome``, ``start``, ``end``, ``transcript_id`` and ``bedstrand`` indexed by\n        ``transcript_id``.\n    \"\"\"\n    coordinates = defaultdict(list)\n    for line in io.load_file(bed_file):\n        contents = line.strip().split(\"\\t\")\n        transcript_id = contents[3].replace(\"_intron\", \"\")\n        coordinates[transcript_id].append(\n            (\n                contents[0],\n                int(contents[1]),\n                int(contents[2]),\n                transcript_id,\n                contents[5],\n            )\n        )\n    logger.info(f\"Extracted features from : {bed_file}\")\n    return coordinates\n</code></pre>"},{"location":"api/logging/","title":"Logging","text":"<p>This module handles logging setup.</p> <p>Setup and configure logging.</p>"},{"location":"api/logging/#isoslam.logging.setup","title":"<code>setup(level='INFO')</code>","text":"<p>Loguru setup with the required logging level and format.</p> <p>Parameters:</p> Name Type Description Default <code>level</code> <code>str</code> <p>Log level, default is \"INFO\", other options \"WARNING\", \"DEBUG\" etc.</p> <code>'INFO'</code> Source code in <code>isoslam/logging.py</code> <pre><code>def setup(level: str = \"INFO\") -&gt; None:\n    \"\"\"\n    Loguru setup with the required logging level and format.\n\n    Parameters\n    ----------\n    level : str\n        Log level, default is \"INFO\", other options \"WARNING\", \"DEBUG\" etc.\n    \"\"\"\n    logger.remove()\n    logger.add(sys.stderr)\n    logger.add(\n        sys.stderr,\n        colorize=True,\n        level=level.upper(),\n        format=\"&lt;green&gt;{time:HH:mm:ss}&lt;/green&gt; \"\n        \"| &lt;level&gt;{level}&lt;/level&gt; | \"\n        \"&lt;magenta&gt;{file}&lt;/magenta&gt;:&lt;magenta&gt;{module}&lt;/magenta&gt;:&lt;magenta&gt;{function}&lt;/magenta&gt;:&lt;magenta&gt;{line}&lt;/magenta&gt;\"\n        \" | &lt;level&gt;{message}&lt;/level&gt;\",\n    )\n</code></pre>"},{"location":"api/processing/","title":"Processing","text":"<p>Entry point, sub-parsers and arguments and processing functions.</p>"},{"location":"api/processing/#isoslam.processing.create_parser","title":"<code>create_parser()</code>","text":"<p>Create a parser for reading options.</p> <p>Parser is created with multiple sub-parsers for eading options to run <code>isoslam</code>.</p> <p>Returns:</p> Type Description <code>ArgumentParser</code> <p>Argument parser.</p> Source code in <code>isoslam/processing.py</code> <pre><code>def create_parser() -&gt; arg.ArgumentParser:\n    \"\"\"\n    Create a parser for reading options.\n\n    Parser is created with multiple sub-parsers for eading options to run ``isoslam``.\n\n    Returns\n    -------\n    arg.ArgumentParser\n        Argument parser.\n    \"\"\"\n    parser = arg.ArgumentParser(\n        description=\"Run various programs related to IsoSLAM. Add the name of the program you wish to run.\"\n    )\n    parser.add_argument(\n        \"-v\",\n        \"--version\",\n        action=\"version\",\n        version=f\"Installed version of IsoSlam : {__version__}\",\n        help=\"Report the installed version of IsoSLAM.\",\n    )\n    parser.add_argument(\n        \"-c\",\n        \"--config-file\",\n        dest=\"config_file\",\n        type=Path,\n        required=False,\n        help=\"Path to a YAML configuration file.\",\n    )\n    parser.add_argument(\n        \"-b\",\n        \"--base-dir\",\n        dest=\"base_dir\",\n        type=Path,\n        required=False,\n        help=\"Base directory to run isoslam on.\",\n    )\n    parser.add_argument(\n        \"-o\",\n        \"--output-dir\",\n        dest=\"output_dir\",\n        type=Path,\n        required=False,\n        help=\"Output directory to write results to.\",\n    )\n    parser.add_argument(\n        \"-l\",\n        \"--log-level\",\n        dest=\"log_level\",\n        type=str,\n        required=False,\n        help=\"Logging level to use, default is 'info' for verbose output use 'debug'.\",\n    )\n\n    subparsers = parser.add_subparsers(title=\"program\", description=\"Available programs listed below:\", dest=\"program\")\n\n    # Create sub-parsers for different stages\n\n    # Process processes all files\n    process_parser = subparsers.add_parser(\n        \"process\",\n        description=\"Process all files and run all summary plotting and statistics.\",\n        help=\"Process all files and run all summary plotting and statistics.\",\n    )\n    process_parser.add_argument(\n        \"-b\",\n        \"--bam-file\",\n        dest=\"bam_file\",\n        type=Path,\n        required=False,\n        help=\"Path to '.bam' file that has undergone read assignment with 'featureCount'.\",\n    )\n    process_parser.add_argument(\n        \"-g\", \"--gtf-file\", dest=\"gtf_file\", type=Path, required=False, help=\"Path to '.gtf' transcript assembly file.\"\n    )\n    process_parser.add_argument(\n        \"-d\",\n        \"--bed-file\",\n        dest=\"bed_file\",\n        type=Path,\n        required=False,\n        help=\"Path to '.bed' utron file. Must be bed6 format.\",\n    )\n    process_parser.add_argument(\n        \"-v\", \"--vcf-file\", dest=\"vcf_file\", type=Path, required=False, help=\"Path to '.vcf.gz' file.\"\n    )\n    process_parser.set_defaults(func=process)\n\n    # Create configuration sub-parser\n    create_config_parser = subparsers.add_parser(\n        \"create-config\",\n        description=\"Create a configuration file using the defaults.\",\n        help=\"Create a configuration file using the defaults.\",\n    )\n    create_config_parser.add_argument(\n        \"-f\",\n        \"--filename\",\n        dest=\"filename\",\n        type=Path,\n        required=False,\n        default=\"config.yaml\",\n        help=\"Name of YAML file to save configuration to (default 'config.yaml').\",\n    )\n    create_config_parser.add_argument(\n        \"-o\",\n        \"--output-dir\",\n        dest=\"output_dir\",\n        type=Path,\n        required=False,\n        default=\"./\",\n        help=\"Path to where the YAML file should be saved (default './' the current directory).\",\n    )\n    create_config_parser.set_defaults(func=io.create_config)\n\n    # Summarise counts sub-parser\n    summary_counts_parser = subparsers.add_parser(\n        \"summary-counts\",\n        description=\"Summarise the counts.\",\n        help=\"Summarise the counts.\",\n    )\n    summary_counts_parser.add_argument(\n        \"--file-pattern\",\n        dest=\"file_pattern\",\n        type=str,\n        required=False,\n        default=\"*_summarized.tsv\",\n        help=\"Regular expression for summarized files to process.\",\n    )\n    summary_counts_parser.add_argument(\n        \"--outfile\",\n        dest=\"outfile\",\n        type=Path,\n        required=False,\n        default=\"summary_counts.tsv\",\n        help=\"Output filename to save results to, will be nested under 'output_dir'.\",\n    )\n    summary_counts_parser.add_argument(\n        \"--separator\",\n        dest=\"sep\",\n        type=str,\n        required=False,\n        default=\"\\t\",\n        help=\"Field separator to use in output file, default is '\\t' but other values (e.g. ',' are allowed).\",\n    )\n    summary_counts_parser.set_defaults(func=summarise_counts)\n\n    # Additional parsers for future functionality\n    # summarize_counts_parser = subparsers.add_parser(\n    #     \"summarize\",\n    #     description=\"Summarize counts.\",\n    #     help=\"Summarize counts.\",\n    # )\n    # summarize_counts_parser.set_defaults(func=summarize_counts)\n    # plot_conversions_parser = subparsers.add_parser(\n    #     \"plot_conversions\",\n    #     description=\"Plot conversions.\",\n    #     help=\"Plot conversions.\",\n    # )\n    # plot_conversions_parser.set_defaults(func=plot_conversions)\n    return parser\n</code></pre>"},{"location":"api/processing/#isoslam.processing.entry_point","title":"<code>entry_point(manually_provided_args=None, testing=False)</code>","text":"<p>Entry point for all IsoSLAM programs.</p> <p>Main entry point for running 'isoslam' which allows the different processing, plotting and testing modules to be run.</p> <p>Parameters:</p> Name Type Description Default <code>manually_provided_args</code> <code>None</code> <p>Manually provided arguments.</p> <code>None</code> <code>testing</code> <code>bool</code> <p>Whether testing is being carried out.</p> <code>False</code> <p>Returns:</p> Type Description <code>None</code> <p>Function does not return anything.</p> Source code in <code>isoslam/processing.py</code> <pre><code>def entry_point(manually_provided_args: list[Any] | None = None, testing: bool = False) -&gt; None | arg.Namespace:\n    \"\"\"\n    Entry point for all IsoSLAM programs.\n\n    Main entry point for running 'isoslam' which allows the different processing, plotting and testing modules to be\n    run.\n\n    Parameters\n    ----------\n    manually_provided_args : None\n        Manually provided arguments.\n    testing : bool\n        Whether testing is being carried out.\n\n    Returns\n    -------\n    None\n        Function does not return anything.\n    \"\"\"\n    parser = create_parser()\n    args = parser.parse_args() if manually_provided_args is None else parser.parse_args(manually_provided_args)\n\n    # If no module has been specified print help and exit\n    if not args.program:\n        parser.print_help()\n        sys.exit()\n\n    if testing:\n        return args\n\n    # Run the specified module(s)\n    args.func(args)\n\n    return None\n</code></pre>"},{"location":"api/processing/#isoslam.processing.process","title":"<code>process(args)</code>","text":"<p>Process a set of files.</p> <p>Parameters:</p> Name Type Description Default <code>args</code> <code>Namespace | None</code> <p>Arguments function was invoked with.</p> required <p>Returns:</p> Type Description <code>None</code> <p>Function does not return anything.</p> Source code in <code>isoslam/processing.py</code> <pre><code>def process(args: arg.Namespace | None) -&gt; None:  # pylint: disable=unused-argument\n    \"\"\"\n    Process a set of files.\n\n    Parameters\n    ----------\n    args : arg.Namespace | None\n        Arguments function was invoked with.\n\n    Returns\n    -------\n    None\n        Function does not return anything.\n    \"\"\"\n    # config = io.read_yaml() if args.config is None else io.read_yaml(args.config) # type: ignore[call-arg,union-attr]\n    return\n</code></pre>"},{"location":"api/processing/#isoslam.processing.summarise_counts","title":"<code>summarise_counts(args)</code>","text":"<p>Take a set of output files and summarise the number of conversions.</p> <p>Counts are made within file, chromosome, transcript, start, end, assignment and whether there is one or more conversion observed.</p> <p>Parameters:</p> Name Type Description Default <code>args</code> <code>Namespace | None</code> <p>Arguments function was invoked with.</p> required <p>Returns:</p> Type Description <code>None</code> <p>Function does not return anything.</p> Source code in <code>isoslam/processing.py</code> <pre><code>def summarise_counts(args: arg.Namespace | None) -&gt; None:\n    \"\"\"\n    Take a set of output files and summarise the number of conversions.\n\n    Counts are made within file, chromosome, transcript, start, end, assignment and whether there is one or more\n    conversion observed.\n\n    Parameters\n    ----------\n    args : arg.Namespace | None\n        Arguments function was invoked with.\n\n    Returns\n    -------\n    None\n        Function does not return anything.\n    \"\"\"\n    # Load the configuration file (default or user) and update with supplied flags\n    config = io.load_and_update_config(args)\n    logger.remove()\n    if vars(args)[\"log_level\"] is not None:\n        logging.setup(level=vars(args)[\"log_level\"])\n    else:\n        logging.setup(level=config[\"log_level\"])\n    summary_counts_config = config[\"summary_counts\"]\n    output_config = summary_counts_config.pop(\"output\")\n    output_config[\"output_dir\"] = config[\"output_dir\"]\n    summary_counts = summary.summary_counts(**summary_counts_config)\n    summary_counts.sort_values(by=[\"Chr\", \"Transcript_id\", \"Start\"], inplace=True)\n    io.data_frame_to_file(summary_counts, **output_config)\n    logger.info(f\"Summary counts file written to : {output_config['output_dir']}/{output_config['outfile']}\")\n</code></pre>"},{"location":"api/summary/","title":"Summary","text":"<p>Functions for summarising output.</p>"},{"location":"api/summary/#isoslam.summary.append_files","title":"<code>append_files(pattern='**/*.tsv', separator='\\t')</code>","text":"<p>Append a set of files into a Pandas DataFrames.</p> <p>Parameters:</p> Name Type Description Default <code>pattern</code> <code>str</code> <p>File name pattern to search for.</p> <code>'**/*.tsv'</code> <code>separator</code> <code>str</code> <p>Separator/delimiter used in files.</p> <code>'\\t'</code> <p>Returns:</p> Type Description <code>DataFrame</code> <p>A Pandas DataFrames of each file found.</p> Source code in <code>isoslam/summary.py</code> <pre><code>def append_files(pattern: str = \"**/*.tsv\", separator: str = \"\\t\") -&gt; pd.DataFrame:\n    \"\"\"\n    Append a set of files into a Pandas DataFrames.\n\n    Parameters\n    ----------\n    pattern : str\n        File name pattern to search for.\n    separator : str\n        Separator/delimiter used in files.\n\n    Returns\n    -------\n    pd.DataFrame\n        A Pandas DataFrames of each file found.\n    \"\"\"\n    _data = io.load_files(pattern, separator)\n    all_data = [data.assign(filename=key) for key, data in _data.items()]\n    return pd.concat(all_data)\n</code></pre>"},{"location":"api/summary/#isoslam.summary.summary_counts","title":"<code>summary_counts(file_pattern='**/*.tsv', separator='\\t', groupby=None, dropna=True)</code>","text":"<p>Count the number of assigned read pairs.</p> <p>Groups the data by</p> <p>Parameters:</p> Name Type Description Default <code>file_pattern</code> <code>str</code> <p>File name pattern to search for.</p> <code>'**/*.tsv'</code> <code>separator</code> <code>str</code> <p>Separator/delimiter used in files.</p> <code>'\\t'</code> <code>groupby</code> <code>list[str]</code> <p>List of variables to group the counts by.</p> <code>None</code> <code>dropna</code> <code>book</code> <p>Whether to drop rows with <code>NA</code> values.</p> <code>True</code> <p>Returns:</p> Type Description <code>DataFrame</code> <p>A Pandas DataFrames of each file found.</p> Source code in <code>isoslam/summary.py</code> <pre><code>def summary_counts(\n    file_pattern: str = \"**/*.tsv\",\n    separator: str = \"\\t\",\n    groupby: list[str] | None = None,\n    dropna: bool = True,\n) -&gt; pd.DataFrame:\n    \"\"\"\n    Count the number of assigned read pairs.\n\n    Groups the data by\n\n    Parameters\n    ----------\n    file_pattern : str\n        File name pattern to search for.\n    separator : str\n        Separator/delimiter used in files.\n    groupby : list[str]\n        List of variables to group the counts by.\n    dropna : book\n        Whether to drop rows with ``NA`` values.\n\n    Returns\n    -------\n    pd.DataFrame\n        A Pandas DataFrames of each file found.\n    \"\"\"\n    if groupby is None:\n        groupby = [\"Transcript_id\", \"Chr\", \"Strand\", \"Start\", \"End\", \"Assignment\", \"Conversions\", \"filename\"]\n    _data = append_files(file_pattern, separator)\n    _data[\"one_or_more_conversion\"] = _data[\"Conversions\"] &gt;= 1\n    groupby.append(\"one_or_more_conversion\")\n    return _data.value_counts(subset=groupby, dropna=dropna).reset_index()\n</code></pre>"},{"location":"api/utils/","title":"Utils","text":"<p>This module contains various utilities used within the package.</p> <p>Utilities and helper functionsfor IsoSLAM.</p>"},{"location":"api/utils/#isoslam.utils.update_config","title":"<code>update_config(config, args)</code>","text":"<p>Update the configuration with any arguments.</p> <p>Parameters:</p> Name Type Description Default <code>config</code> <code>dict</code> <p>Dictionary of configuration (typically read from YAML file specified with '-c/--config '). required <code>args</code> <code>Namespace</code> <p>Command line arguments.</p> required <p>Returns:</p> Type Description <code>dict</code> <p>Dictionary updated with command arguments.</p> Source code in <code>isoslam/utils.py</code> <pre><code>def update_config(config: dict[str, Any], args: dict[str, Any]) -&gt; dict[str, Any]:\n    \"\"\"\n    Update the configuration with any arguments.\n\n    Parameters\n    ----------\n    config : dict\n        Dictionary of configuration (typically read from YAML file specified with '-c/--config &lt;filename&gt;').\n    args : Namespace\n        Command line arguments.\n\n    Returns\n    -------\n    dict\n        Dictionary updated with command arguments.\n    \"\"\"\n    args = vars(args) if isinstance(args, Namespace) else args\n    args_keys = args.keys()\n    for config_key, config_value in config.items():\n        if isinstance(config_value, dict):\n            update_config(config_value, args)\n        else:\n            if config_key in args_keys and args[config_key] is not None and config_value is not args[config_key]:\n                original_value = config[config_key]\n                config[config_key] = args[config_key]\n                logger.info(f\"Updated config config[{config_key}] : {original_value} &gt; {args[config_key]} \")\n    if \"base_dir\" in config.keys():\n        config[\"base_dir\"] = io._str_to_path(config[\"base_dir\"])  # pylint: disable=protected-access\n    if \"output_dir\" in config.keys():\n        config[\"output_dir\"] = io._str_to_path(config[\"output_dir\"])  # pylint: disable=protected-access\n    return config\n</code></pre>"}]}